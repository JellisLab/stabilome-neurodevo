---
title: "Estimate transcription rate and half-life from counts"
output:
  html_notebook:
    toc: true
    number_sections: true
    theme: readable
author: Marat Mufteev
date: "`r format(Sys.time(), 'Generated on %d %B, %Y')`"
---

Upload libraries
```{r}
library(DESeq2)
library(dplyr)
```

Set the path to data directory
```{r}
root = "./data/"
```

Upload drosophila normalized counts data
Column name format: Celltype_Genotype_Timepoint_Replicate
```{r}
normed_tbl = read.csv(paste(root, "normed_counts.csv.gz", sep = ""), header = T)
normed_avg_tbl = read.csv(paste(root, "normed_avg_counts.csv.gz", sep = ""), header = T)
```


## Estimate transcription rate (TR) log2 fold-change


Prepare matrix for DESeq2.
```{r}
include_pseudoreplicate = TRUE

# Depending on your experiment design, consider excluding a pseudoreplicate
if (include_pseudoreplicate) {
  gene.counts = normed_tbl %>% 
                select(gene, contains("_0.5_"), contains("_1_")) %>%
                group_by(gene) %>%
                summarise_all(sum, na.rm = T) %>%
                mutate_at(vars(contains("_1_")), function(x) {x/2})
} else {
  gene.counts = normed_tbl %>% 
                select(gene, contains("_0.5_")) %>%
                group_by(gene) %>%
                summarise_all(sum, na.rm = T)
}

# Remove names of the genes 
counts.data = gene.counts[,c(2:ncol(gene.counts))]

# Convert counts dataframe to matrix and append gene names
counts.data = as.matrix(counts.data)
row.names(counts.data) = gene.counts$gene
```


Run DESeq2
```{r}
samples.list = list()
celltypesA = c("iPS", "NPC", "iPS")
celltypesB = c("NPC", "Neu", "Neu")
for (ind in c(1:3)) {
  # Compared cell types
  cellA = celltypesA[ind]
  cellB = celltypesB[ind]

  # Indices for subsets
  A_indices = grepl(x = colnames(counts.data), pattern = cellA)
  B_indices = grepl(x = colnames(counts.data), pattern = cellB)
  
  # Select data for each assay and celltype
  subset_A = counts.data[, A_indices]
  subset_B = counts.data[, B_indices]
  
  # [Optional] Quantile normalize ranges between replicates
  columns_A = colnames(subset_A)
  subset_A = preprocessCore::normalize.quantiles(as.matrix(subset_A))
  subset_A = data.frame(subset_A)
  colnames(subset_A) = columns_A
  columns_B = colnames(subset_B)
  subset_B = preprocessCore::normalize.quantiles(as.matrix(subset_B))
  subset_B = data.frame(subset_B)
  colnames(subset_B) = columns_B
  
  # Merge Trap and Input data
  # Convert data to counts.
  subset = cbind(subset_A, subset_B) %>% 
           # Convert back to raw counts
           # Not necessary, if you start with raw counts data
           mutate_if(is.numeric, function(x) {as.integer(x/min(na_if(x, 0), na.rm = T))})
  
  # Prepare samples for DESeq
  samples = colnames(subset)
  column.data = data.frame(samples,
                           celltype = gsub("_0.5|_1|_A|_B|_WT", "", samples),
                           row.names = samples)
  
  # Create DESeqDataSet object from matrix with counts
  dds = DESeq2::DESeqDataSetFromMatrix(countData = subset,
                                       colData = column.data,
                                       design =~ celltype)
  
  # Run DESeq pipeline
  dds = DESeq2::DESeq(dds)
  
  # Prepare a dataframe with results
  res = DESeq2::results(dds, contrast=c("celltype", cellB, cellA))
  res = data.frame(res) %>%
        mutate(gene = row.names(counts.data)) %>%
        select(gene, log2FoldChange, lfcSE, pvalue, padj)
  samples.list[[paste(cellB, "_", cellA, sep = "")]] = res
}

# Combine tables for all transitions
TR_shifts = Reduce(x = samples.list, f = function(x, y) {full_join(x, y, by = "gene")})
colnames(TR_shifts) = c("gene", unlist(lapply(X = names(samples.list), 
                                              FUN = function(x) paste0(c("log2FC_", "lfcSE_", "pvalue_", "padj_"), x))))

# Summarise counts data
tbl = data.frame(counts.data) %>% 
      mutate(gene = row.names(counts.data),
             MEAN_A = apply(.[,c(1:2, 7:8)], 1, mean),
             SD_A = apply(.[,c(1:2, 7:8)], 1, sd),
             MEAN_B = apply(.[,c(3:4, 9:10)], 1, mean),
             SD_B = apply(.[,c(3:4, 9:10)], 1, sd),
             MEAN_C = apply(.[,c(5:6, 11:12)], 1, mean),
             SD_C = apply(.[,c(5:6, 11:12)], 1, sd)) %>%
      select(gene, MEAN_A, SD_A, MEAN_B, SD_B, MEAN_C, SD_C)
colnames(tbl) = c("gene", "TR_Neu", "TR_Neu_SD",
                  "TR_iPS", "TR_iPS_SD",
                  "TR_NPC", "TR_NPC_SD")

# Add counts data to the fold-change table
TR_shifts = left_join(TR_shifts, tbl)

# Save data
write.csv(TR_shifts, file = paste(root, "TR_log2FC_deseq2.csv", sep = ""), 
          quote = F, row.names = F)
```


## Estimate steady state (SS) log2 fold-change


Prepare matrix for DESeq2.
```{r}
gene.counts = normed_tbl %>% 
                select(gene, contains("SS")) %>%
                group_by(gene) %>%
                summarise_all(sum, na.rm = T)

# Remove names of the genes 
counts.data = gene.counts[,c(2:ncol(gene.counts))] %>%
              mutate_if(is.numeric, as.integer)

# Convert counts dataframe to matrix and append gene names
counts.data = as.matrix(counts.data)
row.names(counts.data) = gene.counts$gene
```


Run DESeq2
```{r}
samples.list = list()
celltypesA = c("iPS", "NPC", "iPS")
celltypesB = c("NPC", "Neu", "Neu")
for (ind in c(1:3)) {
  # Compared cell types
  cellA = celltypesA[ind]
  cellB = celltypesB[ind]

  # Indices for subsets
  A_indices = grepl(x = colnames(counts.data), pattern = cellA)
  B_indices = grepl(x = colnames(counts.data), pattern = cellB)
  
  # Select data for each assay and celltype
  subset_A = counts.data[, A_indices]
  subset_B = counts.data[, B_indices]
  
  # Merge Trap and Input data
  # Convert data to counts.
  subset = cbind(subset_A, subset_B) 
           # Convert back to counts
           # Not necessary, if you start with raw counts data
           #as.data.frame() %>%
           #mutate_if(is.numeric, function(x) {as.integer(x/min(na_if(x, 0), na.rm = T))})
  
  # Prepare samples for DESeq
  samples = colnames(subset)
  column.data = data.frame(samples,
                           celltype = gsub("_SS|_A|_B|_WT", "", samples),
                           row.names = samples)
  
  # Create DESeqDataSet object from matrix with counts
  dds = DESeq2::DESeqDataSetFromMatrix(countData = subset,
                                       colData = column.data,
                                       design =~ celltype)
  
  # Run DESeq pipeline
  dds = DESeq2::DESeq(dds)
  
  # Prepare a dataframe with results
  res = DESeq2::results(dds, contrast=c("celltype", cellB, cellA))
  res = data.frame(res) %>%
        mutate(gene = row.names(counts.data)) %>%
        select(gene, log2FoldChange, lfcSE, pvalue, padj)
  samples.list[[paste(cellB, "_", cellA, sep = "")]] = res
}

# Combine tables for all transitions
SS_shifts = Reduce(x = samples.list, f = function(x, y) {full_join(x, y, by = "gene")})
colnames(SS_shifts) = c("gene", unlist(lapply(X = names(samples.list), 
                                              FUN = function(x) paste0(c("log2FC_", "lfcSE_", "pvalue_", "padj_"), x))))

# Summarise counts data
tbl = data.frame(counts.data) %>% 
      mutate(gene = row.names(counts.data),
             MEAN_A = apply(.[,1:2], 1, mean),
             SD_A = apply(.[,1:2], 1, sd),
             MEAN_B = apply(.[,3:4], 1, mean),
             SD_B = apply(.[,3:4], 1, sd),
             MEAN_C = apply(.[,5:6], 1, mean),
             SD_C = apply(.[,5:6], 1, sd)) %>%
      select(gene, MEAN_A, SD_A, MEAN_B, SD_B, MEAN_C, SD_C)
colnames(tbl) = c("gene", "SS_Neu", "SS_Neu_SD",
                  "SS_iPS", "SS_iPS_SD",
                  "SS_NPC", "SS_NPC_SD")

# Add counts data to the fold-change table
SS_shifts = left_join(SS_shifts, tbl)

# Save data
write.csv(SS_shifts, file = paste(root, "SS_log2FC_deseq2.csv", sep = ""), 
          quote = F, row.names = F)
```


## Estimate half-life with a ratio method


Prepare matrix for DESeq2
```{r}
include_pseudoreplicate = FALSE


if (include_pseudoreplicate) {
  gene.counts = normed_tbl %>% 
                select(gene, contains("SS"), contains("_0.5_"), contains("_1_")) %>%
                group_by(gene) %>%
                summarise_all(sum, na.rm = T) %>%
                mutate_at(vars(contains("_1_")), function(x) {x/2})
} else {
  gene.counts = normed_tbl %>% 
                select(gene, contains("SS"), contains("_0.5_")) %>%
                group_by(gene) %>%
                summarise_all(sum, na.rm = T)
}

# Remove names of the genes 
counts.data = gene.counts[,c(2:ncol(gene.counts))]

# Convert counts dataframe to matrix and append gene names
counts.data = as.matrix(counts.data)
row.names(counts.data) = gene.counts$gene
```


Run DESeq2
```{r}
samples.list = list()
celltypes = c("iPS_WT", "NPC_WT", "Neu_WT")
for (ind in c(1:3)) {
  # Pick cell types
  cell = celltypes[ind]
  
  # Indices for subsets
  indices = grepl(x = colnames(counts.data), pattern = cell)
  
  # Select data for each celltype
  subset = as.data.frame(counts.data[, indices])
  subset = subset %>%
           mutate_if(is.numeric, function(x) {as.integer(x/min(na_if(x, 0), na.rm = T))})

  # Prepare samples for DESeq
  samples = colnames(subset)
  column.data = data.frame(samples,
                           assay = ifelse(grepl("SS", samples), "SS", "TR"),
                           celltype = gsub("_0.5|_1|_A|_B|_SS", "", samples),
                           row.names = samples) %>%
                mutate(assay = factor(assay, levels = c("TR", "SS")))
  
  # Create DESeqDataSet object from matrix with counts
  dds = DESeq2::DESeqDataSetFromMatrix(countData = subset,
                                       colData = column.data,
                                       design =~ assay)
  
  # Run DESeq pipeline
  dds = DESeq2::DESeq(dds)
  
  res = DESeq2::results(dds)
  res = data.frame(res) %>%
        mutate(gene = row.names(counts.data)) %>%
        select(gene, log2FoldChange, lfcSE, pvalue, padj)
  samples.list[[cell]] = res
}

# Combine tables for each transition
SS_TR_data = Reduce(x = samples.list, f = function(x, y) {full_join(x, y, by = "gene")})
colnames(SS_TR_data) = c("gene", unlist(lapply(X = names(samples.list), 
                                                 FUN = function(x) paste0(c("log2_SS_TR_", "lfcSE_", "pvalue_", "padj_"), x))))

# Save table
output = paste(root, "SS_TR_deseq2.csv", sep = "")
write.csv(SS_TR_data, output, row.names = F)
```


## Estimate half-life with saturation curve


Define function for fitting a saturation curve. This functions is slow. It's better
to run it on a cluster with multiple cores after adapting the code for parallel run in R. 
```{r}
estimate_HL <- function(ind, tbl, celltype) {
  # Subset counts table
  columns = grep(celltype, colnames(tbl))
  times = c(0.5, 1, 4, 8, 24)

  # Prepare counts data for fitting saturation curve
  y = as.numeric(tbl[ind, columns])
  t = times
  
  # In a first pass fit curve roughly without correcting for 
  # dependence of variance on number of counts. Use rough fit to estimate 
  # "true" number of counts Y at each timepoint. Then, correct for 
  # increase in variance in second pass by setting weights W as follows:
  # w = 1/variance ~ 1/Y
  fit <- tryCatch(nls( y ~ C*( 1 - exp( k*t ) ),
                       start=c( C=max(y), k=-0.1 ),
                       lower=c(C=1,k=-5.0), upper=c(C=1e7,k=-0.01),
                       control=list(warnOnly=T) ), 
                  error=function(e) NULL )
  
  # If first pass works, create weights
  if (is.null(fit)) {
    output_vec = rep(NA, 19)
    second_fit = F
  } else {
    second_fit = T
    y_new = coef(fit)["C"]*( 1 - exp( coef(fit)["k"]*t ) )
    w = 1/y_new
  }
  
  if (second_fit) {
    # Correct for variance with weights in a second pass fit
    fit <- tryCatch(nls( y ~ C*( 1 - exp( k*t ) ),
                         start=c( C=max(y), k=-0.1 ),
                         weights=w,
                         lower=c(C=1,k=-5.0), upper=c(C=1e7,k=-0.01),
                         control=list(warnOnly=T) ), 
                    error=function(e) NULL )
    
    if (is.null(fit)) {
      output_vec = rep(NA, 19)
    } else { 
      k = coef(fit)["k"]
      C = coef(fit)["C"]
      
      res_sum = sum((resid(fit))**2*fit$weights)
      quality = res_sum/C**2
      tot_sum = sum((y - mean(y))**2*fit$weights)
      resids = resid(fit)

      # Estimate confidence intervals based on likelihood profile method      
      CI_50 <- tryCatch(confint(fit, level = 0.5), 
                        error=function(e) NULL )
      CI_70 <- tryCatch(confint(fit, level = 0.7), 
                        error=function(e) NULL )      
      if (is.null(CI_50)) {
        CI_50_lower = NA
        CI_50_upper = NA
      } else {
        CI_50_lower = CI_50[2,1]
        CI_50_upper = CI_50[2,2]
      }
      if (is.null(CI_70)) {
        CI_70_lower = NA
        CI_70_upper = NA
      } else {
        CI_70_lower = CI_70[2,1]
        CI_70_upper = CI_70[2,2]
      }

      # Construct output vector. Correct for missing 1H timepoint in Neu20.
      output_vec = c(-log(2)/k, C, quality, res_sum, tot_sum, resids, CI_50_lower, CI_50_upper, CI_70_lower, CI_70_upper, y)
    }
    
  }
  
  if (ind %% 100 == 0) {
    print(ind)
  }
  
  # Give proper names to output
  names(output_vec) = c("HL", "C", "quality", "rsqsum", "totsqsum", 
                        "res_30m", "res_1H", "res_4H", "res_8H", "res_24H",
                        "CI_50_low", "CI_50_high", "CI_70_low", "CI_70_high",
                        "count_30m", "count_1H", "count_4H", "count_8H", "count_24H")
  return(output_vec)
}
```

Fit the data to estimate half-life
```{r}
# Fit data for the first 100 genes of WT neurons
# Two main outputs are the first 2 columns of result_tbl
# The rest columns are auxiliary
res = sapply(X = 1:100, FUN = estimate_HL, 
             normed_avg_tbl %>% select(-contains("SS")), "Neu_WT")
result_tbl = data.frame(t(res))
```



#########



